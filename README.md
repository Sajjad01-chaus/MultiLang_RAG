# Mini RAG Document QA System

A FastAPI-based RAG (Retrieval-Augmented Generation) system for PDF document question-answering using HuggingFace API.

## ğŸš€ Features

- **PDF Upload & Processing**: Upload PDF documents with OCR support
- **RAG Pipeline**: Advanced retrieval and generation using vector search
- **HuggingFace Integration**: Uses HuggingFace Inference API for LLM responses
- **Web Interface**: Streamlit-based UI for easy interaction
- **Docker Support**: Complete containerization with Docker Compose

## ğŸ—ï¸ Architecture

- **FastAPI Backend**: REST API for document processing and queries
- **Qdrant Vector DB**: Vector storage and similarity search
- **Redis + Celery**: Background task processing
- **Streamlit UI**: Web interface for user interaction
- **HuggingFace API**: LLM inference for answer generation

## ğŸ“‹ Prerequisites

- Docker & Docker Compose
- HuggingFace API Key

## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repository
```bash
git clone <repository-url>
cd Cerebralzip
```

### 2. Configure Environment Variables
```bash
# Copy the environment template
cp .env.example .env

# Edit .env file and add your HuggingFace API key
HF_API_KEY=your_huggingface_api_key_here
```

### 3. Build and Run
```bash
docker-compose up --build
```

## ğŸŒ Access Points

- **FastAPI API**: http://localhost:8000
- **Streamlit UI**: http://localhost:8501
- **API Documentation**: http://localhost:8000/docs

## ğŸ“š API Endpoints

### Upload Document
```bash
POST /ingest
Content-Type: multipart/form-data

# Upload a PDF file
curl -X POST "http://localhost:8000/ingest" \
     -F "file=@document.pdf" \
     -F "language=en"
```

### Query Document
```bash
POST /query
Content-Type: application/json

{
  "query": "What is the main topic of this document?"
}
```

### Health Check
```bash
GET /health
```

## ğŸ”§ Configuration

### Environment Variables
- `HF_API_KEY`: Your HuggingFace API key (required)
- `SMALL_LLM_MODEL`: HuggingFace model to use (default: microsoft/DialoGPT-medium)
- `QDRANT_URL`: Qdrant vector database URL
- `REDIS_URL`: Redis URL for task queue
- `EMBED_MODEL`: Sentence transformer model for embeddings

### Models Used
- **LLM**: microsoft/DialoGPT-medium (via HuggingFace API)
- **Embeddings**: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
- **Vector DB**: Qdrant

## ğŸ”’ Security Notes

- `.env` file is gitignored and contains sensitive API keys
- Never commit API keys to version control
- Use environment variables for all sensitive configuration

## ğŸ“ Project Structure

```
â”œâ”€â”€ app/                    # FastAPI application
â”‚   â”œâ”€â”€ app.py             # Main API endpoints
â”‚   â”œâ”€â”€ llm_utils.py       # HuggingFace API integration
â”‚   â”œâ”€â”€ ingest.py          # Document processing
â”‚   â”œâ”€â”€ retrieve.py        # Vector search
â”‚   â””â”€â”€ ...
â”œâ”€â”€ UI/                    # Streamlit interface
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ workers/               # Celery background tasks
â”œâ”€â”€ docker-compose.yaml    # Container orchestration
â”œâ”€â”€ Dockerfile            # Container definition
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ .env.example         # Environment template
```

## ğŸš€ Usage

1. **Upload a PDF**: Use the Streamlit UI or API to upload documents
2. **Ask Questions**: Query the uploaded documents using natural language
3. **Get Answers**: Receive contextual answers with source citations

## ğŸ”§ Development

### Local Development
```bash
# Install dependencies
pip install -r requirements.txt

# Run FastAPI
uvicorn app.app:app --reload

# Run Streamlit
streamlit run UI/app.py
```

### Docker Development
```bash
# Build and run all services
docker-compose up --build

# Run specific service
docker-compose up fastapi
```

## ğŸ“ License

This project is for educational/assignment purposes.

## ğŸ¤ Contributing

This is an assignment submission. Please follow the assignment guidelines for any modifications.
